{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Adversarial attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will carry out adversarial attacks on a neural network trained to identify MNIST digits. An adversarial attack consists of finding a very small perturbation of the network's inputs (a change in the image) that fools the neural network. We will then reinforce the training to try to make the neural network robust to these attacks.\n",
    "\n",
    "In this practice session, some cells must be filled according to the instructions. They are identified by the word **Exercise**. You will perform the **Verifications** yourselves in most cases, by watching if the algorithm correctly works and converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT MODIFY\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply data normalization (division by 255) and change the output data into categorial vectors (one hot encoding with keras.utils.categorical). If you use a Convolutional architecture (CNN), do not forget to add a new axis to the input data, that represents the number of channels (the number of channels is 1 here for grey-scale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO\n",
    "\n",
    "X_train =\n",
    "\n",
    "X_test =\n",
    "\n",
    "Y_train_cat =\n",
    "\n",
    "Y_test_cat ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Load the pre-trained model that you want to attack (or build and train a new model). Call it \"my_model\". You can load a model by using keras.models.load_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = #TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Display your architecture by calling my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification**: If there is no error, everything should be ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply the model for the predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = #TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Extract the predicted labels of the network, that correspond to the classes with the highest predicted probabilites. The function np.argmax will be useful (take care of the \"axis\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred_lab = #TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Compute the accuracy on the test set, and remember it carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell displays randomly some of the test examples and the associated predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(X_test.shape[0])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[r,:,:],cmap = \"hot\")\n",
    "plt.title(\"Network prediction: \" + str(Y_test_pred_lab[r]) + \"\\nTrue value: \" + str(Y_test[r]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_pred_test[r],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Network output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Adapt the previous code to displays random wrong predictions of the network. The function np.where should be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now attack our network by computing adversarial attacks on the input data. Computing an adversarial attack on an example $x$ for a neural network $f_{\\theta}$ consists in finding a perturbation $\\delta$ that maximises the loss function $L$ on the attacked example $x + \\delta$, according to the expected label $y$, with the constraint that $\\delta$ is small (with a norm lower than $\\varepsilon$). Mathematically:\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta^{*} = \\underset{\\lVert \\delta \\rVert < \\varepsilon}{\\mathrm{argmax}}~L(f_{\\theta}(x + \\delta),y)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\delta^{*}$ is the optimal attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the gradient of the loss function according to the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional attack methods consist of calculating the gradient of the cost function with respect to the inputs and then 'raising' this gradient.\n",
    "\n",
    "It is therefore first necessary to calculate this gradient for each input $x$ :\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_x L(f_\\theta(x),y)\n",
    "\\end{equation}\n",
    "\n",
    "**Exercise**: The Tensorflow library has the tools needed to calculate the gradient of one quantity with respect to another quantity, as long as the links between these two quantities are Tensorflow functions. A tensorflow function can be, for example, tf.math.log, tf.math.exp, a simple addition of two quantities, a product, a power... or even a tensorflow (or keras) neural network!\n",
    "The exercise then consists of completing the following function which, for a given input (or set of inputs), a given label and a given model, returns the gradient of the loss function (in this case Categorical CrossEntropy) relative to the inputs.\n",
    "\n",
    "To complete the picture:\n",
    "- In the \"with tf.GradientTape() as tape\" part, we track the inputs variable (it is relative to this variable that we calculate the gradient). This is done using the tape.watch(inputs) command.\n",
    "- We now need to complete the code, still respecting the indentation of gradient.tape, to obtain the loss value associated with these inputs and labels:\n",
    "    - Perform the prediction on the inputs (use model(inputs) and not model.predict(inputs)!, because model(inputs) is a tensorflow operation and model.predict(inputs) is a numpy operation which is not tracked by the gradient).\n",
    "    - Once the prediction has been made, calculate the loss between this prediction and the expected label using loss_cross, defined at the start of the cell.\n",
    "- Then exit the GradientTape indentation and return the gradient of the loss calculated in this way relative to the inputs using tape.gradient(loss,inputs).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cross = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def Calculgradient(inputs, label, model):\n",
    "    \n",
    "    label = tf.reshape(label,(label.shape[0],10))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        tape.watch(inputs)\n",
    "        \n",
    "        prediction = #TO DO\n",
    "        loss = #TO DO\n",
    "    \n",
    "    gradient = #TO DO\n",
    "    \n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  FGSM attack (Fast Gradient Signed Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FGSM attack consists of considering only the sign of each gradient component to find the direction of the attack. This is a very fast attack (a single iteration) and in this case the perturbation is simply:\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta = \\lambda~\\mathrm{sign}( \\nabla_x L(f_\\theta(x),y))\n",
    "\\end{equation}\n",
    "\n",
    "In this case, $\\lambda$ is a coefficient which can be used to select the amplitude of the perturbation. The smaller the $\\lambda$, the more indiscernible but potentially ineffective the attack.\n",
    "\n",
    "**Exercise**: The purpose of the function below is to calculate the perturbation to be applied to each attack using the FGSM method: this perturbation is calculated for inputs, with expected outputs noted label, for a model noted model and with a $\\lambda$ coefficient noted lambd. Use the Calculgradient function defined earlier, and the tf.math.sign function may be useful.\n",
    "\n",
    "Here the inputs are not considered as tf tensors and the labels are not categorical, hence the first two pre-filled lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_fgsm(inputs, label, model, lambd):\n",
    "\n",
    "    inputs_tf = tf.constant(inputs,dtype = \"float32\")\n",
    "    lab = keras.utils.to_categorical(label,num_classes=10)\n",
    "\n",
    "    gradient = #TO DO\n",
    "    delta = #TO DO\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Complete the code below to perform the perturbation prediction on the test data set using delta_fgsm. Here we choose a perturbation amplitude equal to 1 and we will modify the amplitude later when we apply it to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.\n",
    "\n",
    "delta = #TO DO\n",
    "\n",
    "pred_cur = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply the delta perturbation calculated in the previous cell to X_test. The $\\lambda$ term is used to adjust its amplitude (the perturbation will then be $\\lambda \\times \\delta$). Once the adversarial image has been calculated, its limits may exceed the limit intensities of the MNIST images (between 0 and 1 with our normalisation). Use the np.clip function to put the images back between 0 and 1. Finally, perform the model prediction on the adversarial images.\n",
    "\n",
    "Run the following cell to see the effect of the perturbation on your data and prediction.\n",
    "\n",
    "You can change the lambd value to see the effect of the amplitude of the perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 0.2\n",
    "\n",
    "#TO DO\n",
    "\n",
    "x_adv =\n",
    "\n",
    "pred_adv = my_model.predict(x_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT MODIFY\n",
    "\n",
    "i = np.random.randint(np.shape(X_test)[0])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(221)\n",
    "ax1.imshow(X_test[i,:,:,0],cmap = \"Greys_r\")\n",
    "plt.title(\"Original image\")\n",
    "\n",
    "ax2 = plt.subplot(222)\n",
    "ax2.bar(np.arange(10),height = pred_cur[i],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Output of the network\")\n",
    "plt.title(\"Network prediction: \" + str(np.argmax(pred_cur,axis = 1)[i]) + \"\\n True label: \" + str(Y_test[i]))\n",
    "\n",
    "ax3 = plt.subplot(223)\n",
    "ax3.imshow(x_adv[i,:,:,0],cmap = \"Greys_r\")\n",
    "plt.title(\"Adversarial image\")\n",
    "\n",
    "ax4 = plt.subplot(224)\n",
    "ax4.bar(np.arange(10),height = pred_adv[i],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Output of the network\")\n",
    "plt.title(\"Network prediction: \" + str(np.argmax(pred_adv,axis = 1)[i]) + \"\\n True label: \" + str(Y_test[i]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For the different lambd values below, calculate the accuracy of your neural network on the test set under attack. Complete the following loop at each iteration:\n",
    "- Calculate the adversarial examples of the test set according to the lambd_cur amplitude.\n",
    "- Predict the model on these adversarial examples\n",
    "- Calculate the accuracy of the model and store it in accuracy_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd_vec = np.linspace(0,1,50)\n",
    "\n",
    "accuracy_tab = lambd_vec*0.\n",
    "\n",
    "for i in range(np.size(lambd_vec)):\n",
    "    \n",
    "    lambd_cur = lambd_vec[i]\n",
    "    \n",
    "    #TO DO ....\n",
    "    \n",
    "    accuracy_tab[i] = ...\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the evolution of the accuracy of the model as a function of the lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT MODIFY\n",
    "\n",
    "figure = plt.figure(figsize = (10,8))\n",
    "\n",
    "plt.plot(lambd_vec,accuracy_tab,label = \"Adversarial images\",color = \"red\")\n",
    "plt.plot(lambd_vec,accuracy_tab[0] + accuracy_tab*0,label = \"Original images (baseline)\",color = \"blue\")\n",
    "plt.xlabel(\"Amplitude\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set up an adversarial training procedure. For each training period, this consists of calculating the adversarial examples and training the model on these adversarial examples.\n",
    "\n",
    "**Exercise**: Complete the following function so that at each iteration :\n",
    "- calculate the adversarial examples on the training base (don't forget the clip between 0 and 1)\n",
    "- learn the model based on the new training data. A single epoch in each iteration of the loop should suffice.\n",
    "\n",
    "If the learning process is too slow, don't hesitate to stop it whenever you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 100\n",
    "\n",
    "lambd = 0.2\n",
    "\n",
    "for i in range(N_epochs):\n",
    "    \n",
    "    #TO DO ....\n",
    "    \n",
    "    my_model.fit ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Proceed with the evaluation of your new model: first calculate the new perturbations for alpha = 1 then vary the lambd amplitude in the loop to apply the perturbations with these different amplitudes and calculate the accuracy at each amplitude, which you will store in accuracy_tab_robuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd_vec = np.linspace(0,1,50)\n",
    "\n",
    "accuracy_tab_robuste = lambd_vec*0.\n",
    "\n",
    "alpha = 1.\n",
    "\n",
    "delta = #TO DO\n",
    "\n",
    "for i in range(np.size(lambd_vec)):\n",
    "    \n",
    "    lambd_cur = lambd_vec[i]\n",
    "    \n",
    "    #TO DO ....\n",
    "    \n",
    "    accuracy_tab_robuste[i] = #TO DO\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See below for the accuracy gains on the opposing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT MODIFY\n",
    "\n",
    "figure = plt.figure(figsize = (10,8))\n",
    "\n",
    "plt.plot(lambd_vec,accuracy_tab[0] + accuracy_tab*0,label = \"Original images on previous model (baseline)\",color = \"blue\")\n",
    "plt.plot(lambd_vec,accuracy_tab,label = \"Adversarial images on previous model (baseline)\",color = \"red\")\n",
    "plt.plot(lambd_vec,accuracy_tab_robuste[0] + accuracy_tab*0,label = \"Original images on new model\",color = \"purple\")\n",
    "plt.plot(lambd_vec,accuracy_tab_robuste,label = \"Adversarial images on new model\",color = \"orange\")\n",
    "\n",
    "plt.xlabel(\"Amplitude\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible following steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat this exercise with new data. You can also change the attack algorithm, which here consists of a single gradient iteration, but you can also apply a gradient descent in several steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
