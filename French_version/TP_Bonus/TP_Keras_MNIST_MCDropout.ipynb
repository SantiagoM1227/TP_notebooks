{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuxdaL8ExK8l"
   },
   "source": [
    "# TP Programmation avec Keras - Cas MNIST, niveau de confiance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SBMXtaWxK8m"
   },
   "source": [
    "Dans ce TP, nous allons associer un niveau de confiance à nos prédictions en utilisant la méthode du MC-Dropout. Cette méthode consiste à garder le Dropout actif en phase de test, et d'utiliser la propriété aléatoire du Dropout pour obtenir une variabilité sur les sorties du réseau : une grande variabilité implique un faible niveau de confiance et inversement.\n",
    "\n",
    "Dans ce TP, des cellules seront laissées à trous, il faudra les compléter suivant les consignes. Elles seront identifiées par le mot **Exercice**. Les **Vérifications** seront effectuées principalement par vous-mêmes, sur la bonne convergence des algorithmes ou leur bon fonctionnement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSguuu1vxK8n"
   },
   "source": [
    "Ci-dessous, on importe les bibliothèques qui seront utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeOG9mTVxK8n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxYTKsUixK8o"
   },
   "source": [
    "## Mise en place des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO-hY331xK8o"
   },
   "source": [
    "Le code ci-dessous charge les données MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bV3nZ5Q2xK8o",
    "outputId": "39e1de9b-fc4a-46a1-cce1-d1229bb67ccd"
   },
   "outputs": [],
   "source": [
    "#NE PAS MODIFIER\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUVGAgMDxK8o"
   },
   "source": [
    "**Exercice** : Normalisez les données d'entrées en les divisant par 255 et passez les données de sortie sous forme catégorielle (one hot encoding, en utilisant keras.utils.to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BGKBVGnxK8p"
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLGsPJgQxK8p"
   },
   "source": [
    "**Exercice** : Adaptez le nombre de dimensions de X_train et X_test pour utiliser des couches de convolutions 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvfD_kt0xK8p"
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9x5cMDHLxK8q"
   },
   "source": [
    "## Modèle Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u7O7bgAxK8q"
   },
   "source": [
    "### Création du modèle avec convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kq1H4O6TxK8q"
   },
   "source": [
    "**Exercice** : Créez un modèle avec Keras que vous appellerez \"my_model\".\n",
    "\n",
    "**Instructions spécifiques** : \n",
    "- Utilisez le format ci-dessous : ce n'est plus un format séquentiel car il faut une option spécifique pour conserver le Dropout actif lors de la phase de test. Il faut utiliser le format Functional API.\n",
    "- Inspirez vous du format pour créer en séquence :\n",
    "  - x = your_layer_1(arguments)(x)\n",
    "  - x = your_layer_2(arguments)(x)\n",
    "  - ....\n",
    "  - outputs = your_final_layer(arguments)(x)\n",
    "- Pour les couches de Dropout, ajoutez à côté de l'argument x, le mot-clé training = True, qui permet de garder la Dropout actif en phase de prédiction. N'utilisez pas de couche de BatchNormalization avant ou après le Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-aBfHoRBxK8q"
   },
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input((28,28,1))\n",
    "\n",
    "x = keras.layers.Conv2D(#A COMPLETER)(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "#A COMPLETER\n",
    "\n",
    "outputs = #A COMPLETER\n",
    "\n",
    "my_model = keras.models.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7HndFLxK8r"
   },
   "source": [
    "**Exercice** : Affichez la structure de votre modèle avec my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wu0c93ePxK8r",
    "outputId": "33885a1d-1132-43ce-dc46-0f20203cc666"
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg_FLJWqxK8s"
   },
   "source": [
    "**Vérification** : Pour l'instant, il suffit qu'il n'y ait pas d'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue7YpWAHxK8s"
   },
   "source": [
    "### Compilation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xKL6LAbxK8s"
   },
   "source": [
    "**Exercice** : Compilez le modèle avec l'optimizer que vous souhaitez. Mettez une loss function adaptée ainsi qu'une métrique adaptée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiddXvmyxK8s",
    "outputId": "387c772f-a709-4d6f-d9f2-a0defcfdfedb"
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rrO9hecxK8t"
   },
   "source": [
    "**Vérification** : De nouveau, s'il n'y a pas d'erreur et que vous avez suivi les instructions, tout devrait bien se passer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqjUy2iIxK8t"
   },
   "source": [
    "### Mise en place de l'early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtT3xYc0xK8t"
   },
   "source": [
    "**Exercice** : Définissez un early-stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sM9js1fxK8t"
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SDIMh6GxK8t"
   },
   "source": [
    "## L'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "783ccb8YxK8u"
   },
   "source": [
    "**Exercice** : Effectuez l'apprentissage classiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoBEyosmxK8u",
    "outputId": "fc95400d-ccef-4446-9a73-c928f38e5558"
   },
   "outputs": [],
   "source": [
    "learning = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2mNqp0IxK8u"
   },
   "source": [
    "**Vérification** : La loss function devrait diminuer et l'accuracy augmenter. De même pour le jeu de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml3lOdrqxK8u"
   },
   "source": [
    "**Exercice** : Tracez l'évolution de la fonction de coût et de l'accuracy pour le jeu d'entraînement et pour le jeu de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RHwBlrHxK8u",
    "outputId": "b5d31e87-7dce-4575-d744-d16e491b637e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgYO_f6jxK8v"
   },
   "source": [
    "## Prédictions avec le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtkAHEzLxK8v"
   },
   "source": [
    "**Exercice** : Prenez un exemple au hasard et affichez plusieurs fois sa prédiction. Vous remarquerez qu'elle est différente à chaque appel de votre réseau de neurones. N'utilisez pas my_model.predict (cela désactive le Dropout pour les versions les plus récentes de tensorflow), appliquez directement my_model à votre exemple : my_model(exemple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sObgdz-wxK8v",
    "outputId": "89d02165-f8f8-4841-c9c9-5d165059adad"
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kcN3qiB0T0J"
   },
   "source": [
    "Nous allons caractériser la variabilité dans les prédictions. Pour ce faire, nous allons utiliser la théorie de l'information pour construire des métriques adaptées à la caractérisation de ces incertitudes (auto-évaluées par le réseau).\n",
    "\n",
    "Nous allons déjà pour une seul prédiction, caractériser l'incertitude sur cette prédiction en fonction des probabilités associées à chaque classe. L'idée est que, si la prédiction associe une forte probabilité sur une classe et une probabilité faible sur les autres classes, la prédiction est \"sûre d'elle\". Inversement, si elle associe une faible probabilité à toutes les classe, cette prédiction est moins certaine.\n",
    "\n",
    "Cet aspect se caractérise par **l'entropie de Shannon**, définie de la manière suivante : \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{H}(\\hat{Y}) = -\\sum_{i = 1}^{K} \\hat{y_i}\\log(\\hat{y_i}) \n",
    "\\end{equation}\n",
    "\n",
    "Ici l'indice $i$ parcourt l'ensemble des classes considérées dans le problème, $\\hat{y}$ est la prédiction.\n",
    "\n",
    "**Exercice** : Codez l'entropie de Shannon ci-dessous. Considérez que $y$ est un tableau à plusieurs dimensions et que l'on souhaite calculer l'entropie suivant un axe particulier (argument ax) qui représente les différentes classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8p4Bl6vU2FU6"
   },
   "outputs": [],
   "source": [
    "def shannon_entr(y,ax):\n",
    "\n",
    "  entr = #A COMPLETER\n",
    "\n",
    "  return entr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGXkGYjk2EM0"
   },
   "source": [
    "**Vérification** : Exécutez la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UN7RyAG2uyu",
    "outputId": "98824af6-7925-47c0-9137-4c82c43e1279"
   },
   "outputs": [],
   "source": [
    "#NE PAS MODIFIER\n",
    "\n",
    "np.random.seed(seed = 1)\n",
    "\n",
    "y_hat = np.random.rand(3,10)\n",
    "\n",
    "print(shannon_entr(y_hat,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5y-R3Jf29gL"
   },
   "source": [
    "Le résultat doit être [2.84552209 2.71503273 1.79409548]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn-Kd0DH3D67"
   },
   "source": [
    "Maintenant, nous allons effectuer plusieurs prédictions pour un même exemple, nous aurons une variabilité avec le Monte-Carlo Dropout. L'incertitude totale sera caractérisée par l'entropie de Shannon sur la prédiction moyenne. L'incertitude intrinsèque aux données caractérisée par le réseau (incertitude dite aléatoire) sera donnée par la moyenne des entropies de Shannon. Enfin, l'incertitude dûe à la variabilité des modèle sera donnée par la différence entre les deux quantités précédemment calculées.\n",
    "\n",
    "Mathématiquement, cela donne :\n",
    "\n",
    "  - $\\mathcal{H}(\\mathbb{E}_{w}(\\hat{Y}))$ est l'incertitude totale (l'indice $w$ signifie que l'espérance est donnée par la variabilité engendrée par les poids du réseau avec le MC-Dropout)\n",
    "  - $\\mathbb{E}_{w}(\\mathcal{H}(\\hat{Y}))$ est l'incertitude aléatoire\n",
    "  - $\\mathcal{I}(\\hat{Y};w) = \\mathcal{H}(\\mathbb{E}_{w}(\\hat{Y})) - \\mathbb{E}_{w}(\\mathcal{H}(\\hat{Y}))$ est l'incertitude épistémique. On appelle cette quantité l'information mutuelle et caractérise le lien entre la prédiction et la variabilité des poids du réseau dûe au MC-Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di90u1X9xK8v"
   },
   "source": [
    "**Exercice** : Prenez un exemple, dupliquez le une centaine de fois sur l'axe 0 à l'aide de la fonction np.repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSyl1100xK8v"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "X_test_i = X_test[i:(i+1)]\n",
    "\n",
    "X_test_dup = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Effectuez une prédiction sur cet exemple dupliqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_dup = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9uDAytQxK8v"
   },
   "source": [
    "**Exercice** : À partir de cette prédiction, calculez l'incertitude aléatoire. Pour rappel, avec la formule donnée ci-dessus, l'incertitude alétoire correspond à la moyenne des entropies de Shannon sur les différentes prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incert_aleat = #A COMPLETER\n",
    "\n",
    "print(incert_aleat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : De même, à partir de la prédiction, calculez l'incertitude totale : elle correspond à l'entropie de Shannon calculée sur la moyenne des différentes prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incert_tot = #A COMPLETER\n",
    "\n",
    "print(incert_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Enfin, calculez la part épistémique, qui correspond donc à la différence entre l'incertitude totale et la part aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZse7-qixK8v",
    "outputId": "3eecd938-3261-4827-e887-2d95722631a2"
   },
   "outputs": [],
   "source": [
    "incert_epist = #A COMPLETER\n",
    "\n",
    "print(incert_epist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essais sur l'ensemble de la base de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous permet de dupliquer l'ensemble de la base de test une centaine de fois. Il duplique dans un premier temps le vecteur de test le long d'un axe supplémentaire, puis exécute un reshape pour avoir un tableau de dimensions (nombre d'exemples x m_c, dimensions des images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE PAS MODIFIER\n",
    "\n",
    "n_mc = 100\n",
    "\n",
    "X_test_tot_dup = np.expand_dims(X_test,axis = 1)\n",
    "\n",
    "X_test_tot_dup = np.repeat(X_test_tot_dup,n_mc,axis = 1)\n",
    "\n",
    "X_test_tot_dup = np.reshape(X_test_tot_dup,(n_mc*X_test.shape[0],X_test.shape[1],X_test.shape[2],X_test.shape[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ci-dessous permettra d'effectuer des prédictions sur des batchs de données en utilisant directement my_model et non my_model.predict. Cela évite de saturer la mémoire de la machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE PAS MODIFIER\n",
    "\n",
    "def predict_on_batch_with_dropout(model, data, batch_size):\n",
    "    predictions = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch = data[i:i+batch_size]\n",
    "        batch_predictions = model(batch, training=True)\n",
    "        predictions.append(batch_predictions)\n",
    "    return np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Effectuez une prédiction sur cette base de test dupliquée en utilisant la fonction predict_on_batch_with_dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tot = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille de ce tableau de prédiction est maintenant (n_exemples x n_mc, 10). Pour faire un calcul de l'entropie de Shannon, il faut rassembler les prédictions correspondant au même exemple dans une même dimension : l'idée est d'obtenir un tableau de taille finale (n_exemples, n_mc, 10).\n",
    "\n",
    "**Exercice** : Utilisez la fonction np.reshape pour atteindre cette taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tot = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Calculez l'incertitude aléatoire pour l'ensemble des prédictions. Votre résultat doit être un vecteur de taille n_exemples (de taille 10 000).\n",
    "\n",
    "**Hint** : La difficulté principale à gérer est l'axe sur lequel il faut calculer l'entropie puis celui sur lequel il faut calculer la moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incert_aleat_tot = #A COMPLETER\n",
    "\n",
    "print(incert_aleat_tot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : De même, effectuez le calcul de l'incertitude totale pour l'ensemble des prédictions. Stockez aussi le vecteur donnant la moyenne des prédictions dans le vecteur Y_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mean = #A COMPLETER\n",
    "\n",
    "incert_totale_tot = #A COMPLETER\n",
    "\n",
    "print(incert_totale_tot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Enfin, calculez la part épistémique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incert_epist_tot = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Classez les exemples selon la valeur de leur incertitude aléatoire et visualisez ceux avec la plus grande incertitude aléatoire. La fonction np.argsort sera utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xT-QdU-fxK8w",
    "outputId": "ffacd917-f2f8-490a-83cc-7abf203e2618",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_sort = #A COMPLETER\n",
    "\n",
    "index = #A COMPLETER : stockez l'index que vous voulez visualiser dans cette variable\n",
    "\n",
    "label_pred = np.argmax(Y_mean[index])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[index,:,:],cmap = \"hot\")\n",
    "plt.title(\"Prédiction moyenne : \" + str(label_pred) + \"\\n Vraie valeur : \" + str(Y_test[index]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_mean[index],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Valeur\")\n",
    "plt.ylabel(\"Output du réseau\")\n",
    "plt.title(\"Incertitude aléatoire : \" + str(incert_aleat_tot[index]) + \n",
    "          \"\\nIncertitude épistémique : \" + str(incert_epist_tot[index])+\n",
    "          \"\\nIncertitude totale : \" + str(incert_totale_tot[index]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Faites de même pour l'incertitude épistémique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhChSGgOxK8w",
    "outputId": "ca8e21e1-e224-492d-f77b-496b22494799"
   },
   "outputs": [],
   "source": [
    "index_sort = #A COMPLETER\n",
    "\n",
    "index = #A COMPLETER : stockez l'index que vous voulez visualiser dans cette variable\n",
    " \n",
    "label_pred = np.argmax(Y_mean[index])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[index,:,:],cmap = \"hot\")\n",
    "plt.title(\"Prédiction moyenne : \" + str(label_pred) + \"\\n Vraie valeur : \" + str(Y_test[index]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_mean[index],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Valeur\")\n",
    "plt.ylabel(\"Output du réseau\")\n",
    "plt.title(\"Incertitude aléatoire : \" + str(incert_aleat_tot[index]) + \n",
    "          \"\\nIncertitude épistémique : \" + str(incert_epist_tot[index])+\n",
    "          \"\\nIncertitude totale : \" + str(incert_totale_tot[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0rCarbKxK8x"
   },
   "source": [
    "**Exercice** : Enfin, faites de même pour l'incertitude totale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZBwGpnxxK8x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_sort = #A COMPLETER\n",
    "\n",
    "index =  #A COMPLETER : stockez l'index que vous voulez visualiser dans cette variable\n",
    "\n",
    "label_pred = np.argmax(Y_mean[index])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[index,:,:],cmap = \"hot\")\n",
    "plt.title(\"Prédiction moyenne : \" + str(label_pred) + \"\\n Vraie valeur : \" + str(Y_test[index]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_mean[index],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Valeur\")\n",
    "plt.ylabel(\"Output du réseau\")\n",
    "plt.title(\"Incertitude aléatoire : \" + str(incert_aleat_tot[index]) + \n",
    "          \"\\nIncertitude épistémique : \" + str(incert_epist_tot[index])+\n",
    "          \"\\nIncertitude totale : \" + str(incert_totale_tot[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez si vous le souhaitez continue d'étudier ces données, en produisant l'histogramme des incertitudes, en regardant la corrélation entre les incertitudes renvoyées et les erreurs du réseau..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP_Keras_MNIST_CNN_correction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
