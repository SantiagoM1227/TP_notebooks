{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Programmation avec Keras - Cas MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons produire un réseau de neurones pour effectuer une classification sur le cas MNIST avec les bibliothèques keras/tensorflow. MNIST est une base de données composée d'images de chiffres.\n",
    "\n",
    "Ce TP se fera en plusieurs étapes. Dans un premier temps, nous mettrons en place un réseau de neurones simple (fully-connected), sans procédure de régularisation particulière. Puis, nous ajouterons de la régularisation et un jeu de validation, pour essayer d'améliorer les performances de généralisation. Enfin, nous mettrons en place un réseau de neurones de convolution.\n",
    "\n",
    "Dans ce TP, des cellules seront laissées à trous, il faudra les compléter suivant les consignes. Elles seront identifiées par le mot **Exercice**. Les **Vérifications** seront effectuées principalement par vous-mêmes, sur la bonne convergence des algorithmes ou leur bon fonctionnement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous, on importe les bibliothèques qui seront utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous charge les données MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE PAS MODIFIER\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Avec plt.imshow, regardez à quoi ressemble les données de X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : Des images de chiffres doivent apparaître."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Regardez les dimensions des données d'entrée, celle des données de sortie. Affichez aussi sous forme d'un tableau les données d'entrées du premier exemples ainsi que les 15 premières données de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en forme des données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Vous constatez que les données d'entrée sont composées de tableaux de nombres compris entre 0 et 255. Ce sont des nombres relativement grand pour un réseau de neurones, qui peuvent créer des instabilités numériques lors des calculs des gradients. Pour éviter ces instabilités numériques, il convient d'avoir des nombres de l'ordre de l'unité.\n",
    "Pour ce faire, on va simplement normaliser les données en les divisant par 255, valeur maximale des pixels. Faites-le ci-dessous pour X_train et X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = #A COMPLETER\n",
    "\n",
    "X_test = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en forme des données de sortie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Vous constaterez aussi que les données de sortie correspondent au chiffre de l'image (nombre en 0 et 9). Pour effectuer une classification, il faut en fait des classes binaires, dont la valeur est 0 ou 1, avec le nombre de classes attendu. Par exemple, le chiffre 5 sera encodé par le vecteur [0,0,0,0,0,1,0,0,0,0].\n",
    "\n",
    "Pour ce faire, vous pouvez utiliser la fonction de keras keras.utils.to_categorical, en indiquant le vecteur à traiter, ainsi que le nombre de classes avec le mot-clé num-classes. Faites-le pour Y_train et Y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = #A COMPLETER\n",
    "\n",
    "Y_test_cat = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle Keras simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Créez un modèle avec Keras que vous appellerez \"my_model\".\n",
    "\n",
    "**Instructions spécifiques** : \n",
    "- La première couche doit être Flatten avec un input_shape qui correspond à la dimension des données d'entrée. Cette couche permet seulement d'applatir les données en un vecteur : un réseau de type Multilayer Perceptron s'applique en effet à des vecteurs. Il n'y a pas besoin de préciser d'autre variable que les dimensions d'entrée.\n",
    "- On effectue une classification exclusive, il n'y a qu'un seul chiffre affiché : la dernière couche doit faire intervenir la fonction softmax. Mettez aussi le bon nombre de neurones en sortie.\n",
    "- Pour le reste, mettez 2 ou 3 couches intermédiaires, une centaine de neurones, une fonction d'activation relu. Vous êtes assez libres !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Affichez la structure de votre modèle avec my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : Pour l'instant, il suffit qu'il n'y ait pas d'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Compilez le modèle avec l'optimizer que vous souhaitez.\n",
    "\n",
    "**Instructions spécifiques** :\n",
    "- Pour la loss function, nous faisons une classification exclusive, la \"categorical_crossentropy\" pourra être utilisée comme loss function.\n",
    "- Pour la métrique, ce sera \"categorical_accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : De nouveau, s'il n'y a pas d'erreur et que vous avez suivi les instructions, tout devrait bien se passer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Il faut maintenant effectuer l'apprentissage. Attention à bien utiliser Y_train_cat comme donnée de sortie. Stockez l'historique de votre entraînement dans une variable pour pouvoir ensuite afficher l'évolution de la fonction de coût et de l'accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : La loss function devrait diminuer et l'accuracy augmenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Tracez l'évolution de la fonction de coût et de l'accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions avec le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Effectuez la prédiction sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Extrayez les labels prédits par votre réseau, qui correspondent aux classes avec la plus grande probabilité. La fonction np.argmax vous sera utile, à appliquer sur le bon \"axis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Calculez l'accuracy sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous vous permet de visualiser quelques résultats pris au hasard sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(X_test.shape[0])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[r,:,:],cmap = \"hot\")\n",
    "plt.title(\"Prédiction du réseau : \" + str(Y_test_pred_lab[r]) + \"\\n Vraie valeur : \" + str(Y_test[r]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_pred_test[r],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Valeur\")\n",
    "plt.ylabel(\"Output du réseau\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Réutilisez le code d'affichage ci-dessus, mais pour afficher aléatoirement des erreurs. La fonction np.where vous sera utile pour localiser les erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle Keras avec régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en place ici des fonctionnalités un peu plus avancées, liées à la régularisation, batchnormalisation, au jeu de validation, early stopping..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle avec régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Créez un modèle avec Keras que vous appellerez \"my_model\".\n",
    "\n",
    "**Instructions spécifiques** : \n",
    "- La première couche doit être Flatten en mettant le bon input_shape\n",
    "- Faites attention à la dernière couche (nombre de neurones, fonction d'activation)\n",
    "- Placez entre chaque couche une couche de batchnormalization : keras.layers.Batchnormalization. Pas besoin de mettre d'argument. Ne pas utiliser cette couche en sortie.\n",
    "- Placez après chaque batchnormalization une couche de Dropout : keras.layers.Dropout. Il faut mettre en argument le taux de dropout (entre 0 et 1). Essayez quelque chose de l'ordre de 0.1. Ne pas utiliser ce type de couche en sortie.\n",
    "- Dans chaque couche Dense, mettez une régularisation. Utilisez le mot-clé kernel_regularizer dans les couches Dense. Donnez leur ensuite les variables keras.regularizers.l2(1e-3). 1e-3 correspond au paramètre de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Affichez la structure de votre modèle avec my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : Pour l'instant, il suffit qu'il n'y ait pas d'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Compilez le modèle avec l'optimizer que vous souhaitez. Mettez une loss function adaptée ainsi qu'une métrique adaptée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : De nouveau, s'il n'y a pas d'erreur et que vous avez suivi les instructions, tout devrait bien se passer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place de l'early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Nous allons utiliser un jeu de validation lors de l'apprentissage, que vous programmerez par la suite dans my_model.fit. Nous mettrons en place un early stopping sur ce jeu de validation qui arrêtera l'apprentissage lorsque la fonction de coût sur ce jeu de validation ne décroît plus après un certain nombre d'époques.\n",
    "\n",
    "Pour ce faire :\n",
    "- Mettez dans cette variable un keras.callbacks.EarlyStopping(...)\n",
    "- Il faut dire ce qui est surveillé pour cet early stopping. Nous allons utiliser la loss de validation. Pour ce faire, utilisez le mot-clé monitor et affectez-lui la chaîne de caractères \"val_loss\"\n",
    "- Il faut dire pendant combien d'époques d'affilée on surveille si la fonction de coût de validation ne diminue plus. Pour ce faire, utilisez le mot-clé patience et affectez-lui le nombre d'époques que vous souhaitez surveiller. Dans notre cas, une dizaine d'époques devrait suffire.\n",
    "- Enfin, il faut préciser au modèle qu'il doit restaurer les paramètres correspondant à la meilleure valeur de la fonction de coût. Cela se fait en utilisant le mot-clé restore_best_weights et lui affectant True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Il faut maintenant effectuer l'apprentissage. Stockez l'historique de votre entraînement dans une variable pour pouvoir ensuite afficher l'évolution de la fonction de coût et de l'accuracy.\n",
    "\n",
    "**Instructions spécifiques** :\n",
    "- Il faut préciser un jeu de validation. Cela peut se faire en utilisant le mot-clé validation_data et lui donnant un jeu de validation prédéfini sous la forme (X_val,Y_val), si vous avez un tel jeu de validation sous la main. On pourrait par exemple utiliser X_test et Y_test_cat par exemple. Cependant dans notre cas, nous allons conserver le jeu de test pour des tests finaux. L'autre possibilité est de scinder X_train et Y_train_cat en deux parties : une partie sera le jeu d'entraînement et l'autre partie sera conservée pour la validation. Pour ce faire, il faut utiliser le mot-clé validation_split et lui affecter la part des données que vous souhaitez utiliser pour la validation. Vous pouvez utilisez 0.1 par exemple, ce qui signifie que 10 % des données seront utilisées pour la validation.\n",
    "- Il faut aussi préciser l'early stopping. Cela se fait en utilisant le mot-clé callbacks et en lui affectant une liste contenant la variable early_stopping. Il faut effectivement utiliser une liste car plusieurs callbacks peuvent être affectés.\n",
    "- Enfin, utilisez aussi des mini-batchs. Pour ce faire, utilisez le mot-clé batch_size et indiquez la taille des mini-batchs. 128 pourrait faire l'affaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : La loss function devrait diminuer et l'accuracy augmenter. De même pour le jeu de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Tracez l'évolution de la fonction de coût et de l'accuracy pour le jeu d'entraînement et pour le jeu de validation. Les clés à utiliser dans history sont \"val_loss\" et \"val_categorical_accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_evolution = #A COMPLETER\n",
    "acc_evolution = #A COMPLETER\n",
    "val_loss_evolution = #A COMPLETER\n",
    "val_acc_evolution = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions avec le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Effectuez la prédiction sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Extrayez les labels prédits par votre réseau, qui correspondent aux classes avec la plus grande probabilité. La fonction np.argmax vous sera utile, à appliquer sur le bon \"axis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Calculez l'accuracy sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous vous permet de visualiser quelques résultats pris au hasard sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(X_test.shape[0])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[r,:,:],cmap = \"hot\")\n",
    "plt.title(\"Prédiction du réseau : \" + str(Y_test_pred_lab[r]) + \"\\n Vraie valeur : \" + str(Y_test[r]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_pred_test[r],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Valeur\")\n",
    "plt.ylabel(\"Output du réseau\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Réutilisez le code d'affichage ci-dessus, mais pour afficher aléatoirement des erreurs. La fonction np.where vous sera utile pour localiser les erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle Keras avec réseau de convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en place ici des couches de convolution (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification du format des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Nous allons utiliser des couches de convolution à deux dimensions. Ce type de couche attend en entrée des données de taille $n\\times m \\times c$, où $n$ et $m$ sont la taille de l'image, et $c$ correspond au nombre de canaux, il faut donc 3 dimensions au total. Par exemple, une image en couleurs RGB est composée de 3 canaux ($c = 3$). Dans le cas de MNIST, les images sont en niveaux de gris, donc composées d'un seul canal. Cependant, la dimension des images de X_train est (28,28) soit deux dimensions, et il faudrait lui ajouter une dimension pour qu'il y ait le bon nombre de dimensions.\n",
    "\n",
    "Ci-dessous, effectuez cette correction grâce à la fonction np.expand_dims, en ajoutant une dimension sur le dernier axe (mot-clé axis = 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = #A COMPLETER\n",
    "\n",
    "X_test = #A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle avec régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Créez un modèle avec Keras que vous appellerez \"my_model\".\n",
    "\n",
    "**Instructions spécifiques** : \n",
    "- Les premières couches devront être des couches de convolution 2D : keras.layers.Conv2D. En argument, indiquez le nombre de neurones (ou de filtres), quelques-uns devraient suffire, pas la peine d'en mettre des dizaines. Puis, il faut préciser la taille des filtres : quelques pixels seront suffisants. Vous pouvez mettre la taille sous la forme (n,m) si vous souhaitez des filtres rectangulaires ou juste n si vous voulez des filtres carrés. Enfin, vous pouvez aussi préciser une fonction d'activation (de type \"relu\".\n",
    "- La toute première couche de convolution doit comporter l'input_shape. Attention : on a ajouté une dimension.\n",
    "- Faites suivre chaque couche de convolution d'une couche de MaxPooling2D (keras.layers.MaxPooling2D) pour réduire la taille de l'image. Indiquez en argument la taille du pooling (en général 2 est une valeur par défaut).\n",
    "- Ne mettez que quelques couches de convolution (2 ou 3 devraient suffire).\n",
    "- A la suite de la partie convolutive, applatissez la réponse grâce à une couche de Flatten, sans argument.\n",
    "- Ensuite, vous pouvez remettre des couches Dense pour compléter le réseau, et finir par une dernière couche avec le nombre de neurones et la fonction d'activation adaptée.\n",
    "- Vous pouvez ajouter des couches de BatchNormalization, Dropout et de la régularisation si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Affichez la structure de votre modèle avec my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : Pour l'instant, il suffit qu'il n'y ait pas d'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Compilez le modèle avec l'optimizer que vous souhaitez. Mettez une loss function adaptée ainsi qu'une métrique adaptée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : De nouveau, s'il n'y a pas d'erreur et que vous avez suivi les instructions, tout devrait bien se passer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place de l'early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Définissez un early-stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Effectuez l'apprentissage avec un jeu de validation, des mini-batchs, l'early-stopping... et stockez l'historique dans une variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification** : La loss function devrait diminuer et l'accuracy augmenter. De même pour le jeu de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Tracez l'évolution de la fonction de coût et de l'accuracy pour le jeu d'entraînement et pour le jeu de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions avec le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Effectuez la prédiction sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Extrayez les labels prédits par votre réseau, qui correspondent aux classes avec la plus grande probabilité. La fonction np.argmax vous sera utile, à appliquer sur le bon \"axis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Calculez l'accuracy sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous vous permet de visualiser quelques résultats pris au hasard sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randint(X_test.shape[0])\n",
    "\n",
    "figure = plt.figure(figsize = (16,9))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(X_test[r,:,:,0],cmap = \"hot\")\n",
    "plt.title(\"Prédiction du réseau : \" + str(Y_test_pred_lab[r]) + \"\\n Vraie valeur : \" + str(Y_test[r]))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(10),height = Y_pred_test[r],tick_label = np.arange(10))\n",
    "plt.xlabel(\"Valeur\")\n",
    "plt.ylabel(\"Output du réseau\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** : Réutilisez le code d'affichage ci-dessus, mais pour afficher aléatoirement des erreurs. La fonction np.where vous sera utile pour localiser les erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A COMPLETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
